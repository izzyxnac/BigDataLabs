services:
  hadoop-master:
    image: yassern1/hadoop-spark-jupyter:1.0.3
    container_name: hadoop-master
    hostname: hadoop-master
    ports:
      - "9870:9870"   # HDFS NameNode
      - "8088:8088"   # YARN ResourceManager
      - "7077:7077"   # Spark Master
      - "19888:19888" # JobHistory Server
      - "8080:8080"   # Spark Web UI
      - "9000:9000"   # HDFS RPC
    volumes:
      - C:\Users\oussa\OneDrive\Documents\hadoop_project/:/shared_volume
    networks:
      - hadoop
    # CORRECTION : On force le démarrage SSH via init.d et on attend 2 secondes
    command: 
      - /bin/bash
      - -c
      - "/etc/init.d/ssh start && sleep 2 && ./start-hadoop.sh && mapred --daemon start historyserver && tail -f /dev/null"
    tty: true
    stdin_open: true

  hadoop-slave1:
    image: yassern1/hadoop-spark-jupyter:1.0.3
    container_name: hadoop-slave1
    hostname: hadoop-slave1
    ports:
      - "8040:8042"
    networks:
      - hadoop
    # On démarre aussi SSH sur les esclaves
    command: ["/bin/bash", "-c", "/etc/init.d/ssh start && tail -f /dev/null"]
    tty: true
    stdin_open: true

  hadoop-slave2:
    image: yassern1/hadoop-spark-jupyter:1.0.3
    container_name: hadoop-slave2
    hostname: hadoop-slave2
    ports:
      - "8041:8042"
    networks:
      - hadoop
    command: ["/bin/bash", "-c", "/etc/init.d/ssh start && tail -f /dev/null"]
    tty: true
    stdin_open: true

networks:
  hadoop:
    driver: bridge
    name: hadoop